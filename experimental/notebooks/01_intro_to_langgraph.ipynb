{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6fb70c",
   "metadata": {},
   "source": [
    "# Introduction to Langgraph Agents\n",
    "\n",
    "Welcome to `tableau-langchain` where you will learn to augment AI agents with the tools to interact with your Tableau environment to make use of all of the powerful analytics and datasources your team has built.\n",
    "\n",
    "![tableau products](./assets/tableau_products.png)\n",
    "\n",
    "This project was written for the open source  [Langchain](https://www.langchain.com/) and [Langgraph](https://www.langchain.com/langgraph) frameworks in Python. These frameworks are very popular with developers and you may find teams at your organization who are already using them. \n",
    "\n",
    "Before you incorporate analytics into your agent we should first establish foundational knowledge regarding how these agents work. The most basic agent by definition requires a Large Language Model (LLM) like ChatGPT or Anthropic and an agent \"tool\". This means that rather than just interacting with a model directly, you equip this model to perform a defined action for you. The following guide was inspired by this official Langchain article explaining how to use the [pre-built ReAct agent](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/).\n",
    "\n",
    "This is our starting point into the world of AI agents. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788cbac5",
   "metadata": {},
   "source": [
    "### Understanding Our Learning Environment: Jupyter Notebook\n",
    "\n",
    "What you're looking at right now is a **Jupyter Notebook**! Think of it as a special kind of document that allows us to beautifully blend explanations and instructions (like what you're reading now!) with actual, executable code.\n",
    "\n",
    "This means you won't just be reading about how to use Tableau with Langchain – you'll have the exciting opportunity to **run the code snippets directly within this notebook** and see the results for yourself. It's a fantastic way to learn because you can actively participate and experiment as we go along. So, get ready to get your hands on the code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5977af3e",
   "metadata": {},
   "source": [
    "### Importing Necessary Building Blocks\n",
    "\n",
    "Alright, let's get started by bringing in the essential tools we'll need. We're going to call upon specific parts of the Langchain and Langgraph libraries that contain pre-built components, kind of like LEGO bricks, that will help us construct our intelligent agent.\n",
    "\n",
    "Specifically, we'll be importing from the `langchain_openai` and `langgraph.prebuilt` packages. These contain the fundamental building blocks we'll use to assemble our agent and get it working with Tableau. Think of these imports as gathering all the necessary ingredients before we start cooking!\n",
    "\n",
    "You might notice that we're specifically using **OpenAI** as our Large Language Model (LLM) in this tutorial. This is a deliberate choice for our demonstration.\n",
    "\n",
    "However, it's really important to understand that **Langchain is incredibly flexible!** It acts as a universal gateway, allowing you to connect to a vast ecosystem of other LLMs. So, while we're focusing on OpenAI today, keep in mind that Langchain (and Tableau as a tool) can seamlessly integrate with many other language models out there, giving you lots of options for your projects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5951087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langgraph packages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7951126",
   "metadata": {},
   "source": [
    "### Connecting Our Agent to the Outside World: API Keys and Environment Variables\n",
    "\n",
    "For our agent to interact with external services and information – a very common task – it often needs to communicate using **REST API calls**. Think of APIs as digital doorways that allow different software systems to talk to each other.\n",
    "\n",
    "Now, just like using a key to open a physical door, many APIs require **API keys** to ensure that the requests being made are authorized and legitimate. In our example, to leverage the power of the **OpenAI platform** as our Large Language Model, we'll need an OpenAI API key.\n",
    "\n",
    "To keep things organized and secure, we've created a special file called an **environment file**. This file acts as a central storage location where we can keep all our important API keys and other configuration details in one place. This makes it much easier to manage them and prevents us from hardcoding sensitive information directly into our code.\n",
    "\n",
    "In the next step, we'll show you how to access these variables from our environment file within our code. This way, when we start building our agent, all the necessary credentials will be readily available without having to enter them one by one in our main program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a455e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# loads environment variables into Python script\n",
    "load_dotenv()\n",
    "\n",
    "# attribute and print the open api key from the environment variables to a variable\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "print(\"This is the OpenAI key we are using: \",openai_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5009b88",
   "metadata": {},
   "source": [
    "### Initializing Langchain with OpenAI\n",
    "\n",
    "Alright, let's get the ball rolling by telling Langchain that we want to use OpenAI as our language model. We're making a conscious choice here to use the **`gpt-4o-mini`** model.\n",
    "\n",
    "You might be interested to know that `gpt-4o-mini` is a fantastic option because it provides a great balance of performance and affordability. For the purposes of this tutorial and the tasks we'll be tackling, its capabilities are more than sufficient, saving us from incurring the higher costs associated with more advanced (and often overkill for our needs) LLM models. So, we'll be sticking with `gpt-4o-mini` for this learning journey!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cea4eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we initialize the model we want to use.\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7014a942",
   "metadata": {},
   "source": [
    "### Defining a Custom Tool: Getting Weather Information\n",
    "\n",
    "In this section, we're going to create our very own **custom tool** that our Langchain agent can use. Think of tools as specific skills or functions that we equip our agent with to help it interact with the world or access information.\n",
    "\n",
    "For the purpose of this tutorial, we'll keep things simple and create a tool called `get_weather`. This tool will provide pre-defined weather updates for two specific cities: New York City (NYC) and San Francisco (SF).\n",
    "\n",
    "While this is a simplified example, it demonstrates the fundamental concept of how you can create and integrate custom functionalities into your Langchain agents. This allows you to tailor your agent's capabilities to your specific needs and connect it to various data sources or actions.\n",
    "\n",
    "Let's take a look at the Python code that defines this `get_weather` tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78ff80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For this tutorial we will use custom tool that returns pre-defined values for weather in two cities (NYC & SF)\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Use this to get weather information.\"\"\"\n",
    "    if city == \"nyc\":\n",
    "        return \"It might be cloudy in nyc\"\n",
    "    elif city == \"sf\":\n",
    "        return \"It's always sunny in sf\"\n",
    "    else:\n",
    "        raise AssertionError(\"Unknown city\")\n",
    "\n",
    "\n",
    "tools = [get_weather]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445cddbe",
   "metadata": {},
   "source": [
    "### Building Our Agent's Brain: Defining the Graph\n",
    "\n",
    "Now that we have our language model (`model`) initialized and our custom weather tool (`tools`) ready, it's time to put them together and define how our agent will think and act. We'll be using Langraph's `create_react_agent` function to do this.\n",
    "\n",
    "Think of this step as designing the core logic or \"brain\" of our agent. The `create_react_agent` function sets up a specific type of agent known as a \"ReAct\" agent. ReAct stands for \"Reason + Act,\" and it's a powerful framework that allows our agent to not only take actions (like using our `get_weather` tool) but also to reason about what actions to take and why.\n",
    "\n",
    "By calling `create_react_agent` with our language model and the available tools, we're essentially defining the fundamental structure that will govern how our agent processes information, decides on its next steps, and ultimately interacts with the world (in this case, by using our weather tool). Let's see the code that brings this agent graph to life:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368bd338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the graph\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "graph = create_react_agent(model, tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464aaf43",
   "metadata": {},
   "source": [
    "### Visualizing Our Agent's Structure\n",
    "\n",
    "To get a clearer picture of the internal workings of the agent we just created, Langraph provides a fantastic visualization capability. This allows us to see a visual representation of how the different components of our agent are connected and how information flows through it.\n",
    "\n",
    "Think of it as getting an architectural blueprint of our agent's \"brain.\" This visual representation can be incredibly helpful for understanding the decision-making process and the sequence of steps our agent will take when interacting with the world.\n",
    "\n",
    "Below is the code that will generate this visual diagram. It leverages the `get_graph()` method of our `graph` object and then uses `draw_mermaid_png()` to create a clear and easily understandable image of our agent's structure. Let's take a look and see what our agent looks like under the hood!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2762c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e0273e",
   "metadata": {},
   "source": [
    "### Observing Our Agent in Action: The `print_stream` Function\n",
    "\n",
    "To truly understand how our agent operates, it's incredibly useful to see its internal thought process and the actions it takes in real-time. The following code defines a helper function called `print_stream`.\n",
    "\n",
    "This function is designed to take the output stream from our Langraph agent and neatly display the intermediate steps and the final responses. As the agent reasons and interacts with tools, the `print_stream` function will print out the messages and actions it's taking, allowing us to follow along with its decision-making process.\n",
    "\n",
    "Think of this as having a window into the agent's mind as it works. By observing the stream of messages, we can gain valuable insights into how the ReAct framework is guiding the agent's reasoning and actions. Let's look at the code that will allow us to observe our agent in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329a892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58a9f47",
   "metadata": {},
   "source": [
    "### And Now, the Moment We've Been Waiting For! Let's Interact with Our Agent! 🥁\n",
    "\n",
    "The moment has arrived! We're finally going to put our newly created agent to the test and see it in action.\n",
    "\n",
    "Before we do, there's one crucial step: **you need to provide the instruction, or \"prompt,\" that you want to give to our agent.** In the code snippet below, you'll see a placeholder: `[ENTER YOUR PROMPT HERE]`.\n",
    "\n",
    "**Please replace this placeholder with your own prompt.** To see our custom `get_weather` tool in action, make sure your prompt asks about the weather in either **San Francisco** or **New York City**.\n",
    "\n",
    "**Go ahead and edit the code cell below with your chosen prompt!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339105bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_prompt = \"[ENTER YOUR PROMPT HERE]\"\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", your_prompt)]}\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b582f3",
   "metadata": {},
   "source": [
    "Now, as a side quest, will you be able to edit the previous prompt so that you get the weather in New York City **without** using the letters`N`, `Y`, and `C`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eda415",
   "metadata": {},
   "source": [
    "### Testing the Agent's General Knowledge: A Tool-Free Query\n",
    "\n",
    "Alright, let's see how our agent handles a question that doesn't require the use of our specific `get_weather` tool. This will help us understand its general knowledge capabilities.\n",
    "\n",
    "Just like before, you'll find a placeholder `[ENTER YOUR PROMPT HERE]` in the code snippet below.\n",
    "\n",
    "**Please replace this placeholder with a question that is not related to the weather in New York City or San Francisco.** Think of something that our language model should be able to answer based on its training data, without needing to consult any external tools. For example, you could ask:\n",
    "\n",
    "* \"What is the capital of France?\"\n",
    "* \"Tell me a fun fact about San Diego.\"\n",
    "* \"Imagine you are a playful AI assistant for a Tableau enthusiast attending the TC25 San Diego conference. Write a short, rhyming limerick about their excitement for learning new data visualization and AI tricks, and maybe even spotting a Tableau Visionary by the beach.\"\n",
    "\n",
    "**Go ahead and edit the code cell below with your chosen non-weather-related prompt!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98adb475",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_prompt = \"[ENTER YOUR PROMPT HERE]\"\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", your_prompt)]}\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd947b3",
   "metadata": {},
   "source": [
    "### Wrapping Up Part 1: Intro to LangGraph!\n",
    "\n",
    "Excellent work! In this first part of our tutorial, we've successfully covered some fundamental concepts:\n",
    "\n",
    "* We understood the interactive nature of **Jupyter Notebooks**.\n",
    "* We imported the necessary building blocks from **Langchain** and **Langraph**.\n",
    "* We discussed our choice of **OpenAI's `gpt-4o-mini`** as our Language Model and Langchain's flexibility with other LLMs.\n",
    "* We explored the importance of **API keys** and how **environment variables** help us manage them securely.\n",
    "* We initialized **Langchain** to work with our chosen OpenAI model.\n",
    "* We created a **custom tool** (`get_weather`) to extend our agent's capabilities.\n",
    "* We defined the **agent's logic** using Langraph's `create_react_agent`.\n",
    "* We visualized the **agent's structure** to better understand its internal workings.\n",
    "* We used the `print_stream` function to **observe our agent in action** with different types of prompts.\n",
    "\n",
    "You're absolutely right! While we've built a functional Langchain agent with a custom tool, we haven't yet integrated **Tableau**.\n",
    "\n",
    "Fear not! We're just getting started. This first notebook has laid the essential groundwork for understanding how Langchain agents work and how they can be equipped with tools.\n",
    "\n",
    "Now, it's time to take things to the next level and explore how we can bring the power of **Tableau** into the Langchain framework. Let's move on to our **second Jupyter Notebook**, where we'll dive into the exciting world of integrating Tableau with our intelligent agents! Onward! 🎉"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tableau_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
